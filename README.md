# Neural Point Processes for Sparse Air Pollution Regression

This repository implements Neural Point Processes (NPPs) for pixel-wise regression with sparse supervision, and applies them to the task of estimating urban air pollution (PM2.5) from a small set of sensor readings.

Unlike typical image regression tasks with dense labels, here the goal is to predict pollution levels at every pixel in a 2D grid from:
- a small set of sparse ground-truth labels (sensor readings),
- image-like features constructed from static context (e.g., satellite imagery, elevation),
- dynamic features (e.g., interpolated temperature, humidity, PM2.5 history).

<p align="center">
  <img src="figures/pixelwise_regression.png" width="700"/>
</p>

---

## ğŸŒ Why Air Pollution?

Air pollution monitoring suffers from spatial sparsity: sensors are costly, often solar-powered, and can fail intermittently.  
This makes traditional grid-based training ineffective. We need models that generalize across space and can adapt to new sensor readings at test time.

Neural Point Processes (NPPs) are ideal for this:
- They model per-image Gaussian Processes with CNN-predicted means.
- They naturally enforce spatial smoothness using a learnable kernel.
- They allow test-time refinement using newly revealed sensor values.

---

## ğŸ§  Key Features

- End-to-end pipeline for training and evaluating NPPs on real-world PM2.5 sensor data.
- Construction of multichannel inputs from sensor time series and static map layers.
- Spatial interpolation with guaranteed alignment of sensor coordinates.
- Multi-crop data augmentation: each image generates valid random crops with at least one sensor.
- Support for multiple loss modes: MSE baseline and full NPP kernel loss.
- Easy comparison with classical ML models (Random Forest, SVR, Ridge, KNN).

---

## ğŸ—‚ Repository Structure

```
npp_experiment/
â”œâ”€â”€ datasets/             # Data loaders for full-frame and cropped datasets
â”‚   â”œâ”€â”€ sensor_image_dataset.py
â”‚   â”œâ”€â”€ multi_crop_sensor_dataset.py
â”œâ”€â”€ models/               # Autoencoder, MSE model, NPP model, GP kernel
â”‚   â”œâ”€â”€ autoencoder.py
â”‚   â”œâ”€â”€ mse_model.py
â”‚   â”œâ”€â”€ npp_model.py
â”œâ”€â”€ training/             # Training loop and evaluation metrics
â”‚   â””â”€â”€ train_eval.py
â”œâ”€â”€ utils/                # Interpolation, visualization, feature extractors
â”‚   â”œâ”€â”€ interpolation.py
â”‚   â”œâ”€â”€ features.py
â”œâ”€â”€ main/
â”‚   â””â”€â”€ run_experiment.py # Full experiment: training + evaluation + comparison
â”œâ”€â”€ figures/              # Visuals for report/manuscript
â””â”€â”€ data/                 # Not included in repo â€“ must be added manually
```

---

## âš™ï¸ Setup

```bash
git clone https://github.com/yourusername/npp_experiment.git
cd npp_experiment

# Create a conda environment
conda create -n npp python=3.9
conda activate npp

# Install requirements
pip install -r requirements.txt
```

---

## ğŸ“Š Data Preparation

Place your input data in the following structure:

```
data/Pollution/Brookline/
â”œâ”€â”€ pm25.csv
â”œâ”€â”€ temp.csv
â”œâ”€â”€ rh.csv
â”œâ”€â”€ sensor_data_with_elevation.csv
â”œâ”€â”€ sens_code.pkl
â”œâ”€â”€ image_map.png
â”œâ”€â”€ image_sat.png
```

All time series must be hourly aligned. Static layers like satellite images or maps are resized and aligned to the sensor bounding box using `PIXELS_PER_DEGREE`.

---

## ğŸš€ Running the Experiment

Run everything from data processing to evaluation with:

```bash
python -m main.run_experiment
```

This will:
- Load and interpolate sensor data
- Build and normalize multi-channel images
- Generate crops with at least one labeled sensor
- Train MSE and NPP models
- Evaluate on temporally held-out test set
- Train classical baselines for comparison

Results (MSE, RÂ²) are printed and plotted.

---

## ğŸ” Baselines and Models

| Model         | Description                              |
|---------------|-------------------------------------------|
| MSE Autoencoder | CNN trained with standard MSE on sensor pixels |
| NPP (ours)    | CNN + GP kernel loss (static or predicted kernel) |
| Ridge         | Linear regression on temporal sensor features |
| SVR           | Support Vector Regression on same features |
| Random Forest | Tree ensemble using local temporal features |
| KNN           | Nearest neighbor in temporal feature space |

---

## ğŸ“ˆ Example Outputs

- Per-pixel predictions overlaid with true sensor values.
- Evaluation curves: MSE, RÂ² by epoch.
- Model comparison bar plots.

---

## ğŸ›  Customization

| To change                      | Edit in                                  |
|-------------------------------|-------------------------------------------|
| Lookback window               | `LOOKBACK_HOURS` in `run_experiment.py`   |
| Kernel type (fixed, learned)  | `kernel_mode` in `NPPModel`               |
| Crop size / number            | `multi_crop_sensor_dataset.py`            |
| Sensor interpolation method   | `utils/interpolation.py`                  |
| Normalization                 | Dataset construction stats                |
| Loss function                 | `train_eval.py`, model class              |

---

## ğŸ“š Citation

If you use this work, please cite the NPP paper:

```bibtex
@inproceedings{shi2025neural,
  title={Neural Point Processes for Pixel-wise Regression},
  author={Shi, C. and Ã–zcan, G. and Sirera PerellÃ³, M. and Li, Y. and Iftikhar, N. and Ioannidis, S.},
  booktitle={Proceedings of the 28th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  year={2025}
}
```

---

## ğŸ“„ License

MIT License.  
See `LICENSE` file for full terms.

---

## ğŸ™Œ Acknowledgements

This project builds upon the foundational Neural Point Process codebase and adapts it to a new domain: environmental monitoring.  
Special thanks to open air-quality initiatives for releasing high-resolution PM2.5 data and to the AISTATS 2025 authors for foundational theory.